{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f260ee-4403-4e6d-9379-12df4cc8a994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: xgboost in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b41c4e-5f72-4c1f-95b9-781d0ffad158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c365b2e-f956-4f7e-89bd-56ab05b95a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOUSEID</th>\n",
       "      <th>PERSONID</th>\n",
       "      <th>WTPERFIN</th>\n",
       "      <th>WTPERFIN5D</th>\n",
       "      <th>WTPERFIN2D</th>\n",
       "      <th>R_AGE</th>\n",
       "      <th>R_SEX</th>\n",
       "      <th>R_RELAT</th>\n",
       "      <th>WORKER</th>\n",
       "      <th>DRIVER</th>\n",
       "      <th>...</th>\n",
       "      <th>URBAN</th>\n",
       "      <th>URBANSIZE</th>\n",
       "      <th>URBRUR</th>\n",
       "      <th>PPT517</th>\n",
       "      <th>YOUNGCHILD</th>\n",
       "      <th>RESP_CNT</th>\n",
       "      <th>URBRUR_2010</th>\n",
       "      <th>TDAYDATE</th>\n",
       "      <th>WRKCOUNT</th>\n",
       "      <th>STRATUMID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9000013002</td>\n",
       "      <td>1</td>\n",
       "      <td>3938.688806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13363.809355</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>202202</td>\n",
       "      <td>1</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9000013016</td>\n",
       "      <td>1</td>\n",
       "      <td>3183.420810</td>\n",
       "      <td>4177.234452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>202202</td>\n",
       "      <td>2</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000013026</td>\n",
       "      <td>1</td>\n",
       "      <td>7727.266827</td>\n",
       "      <td>11702.302620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>202202</td>\n",
       "      <td>1</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9000013039</td>\n",
       "      <td>1</td>\n",
       "      <td>12167.712239</td>\n",
       "      <td>12540.688961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>202201</td>\n",
       "      <td>1</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000013041</td>\n",
       "      <td>1</td>\n",
       "      <td>3206.344095</td>\n",
       "      <td>4228.326233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>202201</td>\n",
       "      <td>1</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HOUSEID  PERSONID      WTPERFIN    WTPERFIN5D    WTPERFIN2D  R_AGE  \\\n",
       "0  9000013002         1   3938.688806      0.000000  13363.809355     39   \n",
       "1  9000013016         1   3183.420810   4177.234452      0.000000     32   \n",
       "2  9000013026         1   7727.266827  11702.302620      0.000000     44   \n",
       "3  9000013039         1  12167.712239  12540.688961      0.000000     38   \n",
       "4  9000013041         1   3206.344095   4228.326233      0.000000     37   \n",
       "\n",
       "   R_SEX  R_RELAT  WORKER  DRIVER  ...  URBAN  URBANSIZE  URBRUR  PPT517  \\\n",
       "0      2        7       2       1  ...      1          4       1       2   \n",
       "1      2        7       1       1  ...      1          2       1       0   \n",
       "2      1        7       1       1  ...      1          4       1       0   \n",
       "3      1        7       1       1  ...      1          4       1       2   \n",
       "4      1        7       1       1  ...      1          3       1       0   \n",
       "\n",
       "   YOUNGCHILD  RESP_CNT  URBRUR_2010  TDAYDATE  WRKCOUNT  STRATUMID  \n",
       "0           0         4            1    202202         1       1021  \n",
       "1           0         2            1    202202         2       1021  \n",
       "2           0         1            1    202202         1       1021  \n",
       "3           0         4            1    202201         1       1021  \n",
       "4           0         1            1    202201         1       1021  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = r\"E:\\Research\\A NHTS\\NHTS Dataset\\merged_data_clean.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check the first few rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8165f88c-f8e1-4f8e-a1bd-b208f40665c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COV1_OHD\n",
      "1    4289\n",
      "0    3479\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert the COV1_OHD to binary (0 and 1) based on your criteria\n",
    "df['COV1_OHD'] = df['COV1_OHD'].apply(lambda x: 0 if x == 1 else (1 if x in [2, 3, 4] else x))\n",
    "# Check the counts of the binary variable\n",
    "print(df['COV1_OHD'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67cb4f98-9e4e-4bc1-8e10-19a5ebbcd0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define independent variables (IVs) and dependent variable (DV)\n",
    "X = df[['R_AGE', 'HHFAMINC_IMP', 'EDUC', 'DELIV_FOOD', 'DELIV_GROC', 'COV2_OHD', 'COV1_WK', 'HOMEOWN']]\n",
    "y = df['COV1_OHD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6a9314c-1046-4590-b72b-f11be6f0fbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 6214\n",
      "Number of test samples: 1554\n",
      "Train and test datasets saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the number of samples in each set\n",
    "print(f\"Number of training samples: {X_train.shape[0]}\")\n",
    "print(f\"Number of test samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Save the train and test datasets to CSV files\n",
    "X_train_df = pd.DataFrame(X_train, columns=X.columns)  # Convert X_train to DataFrame\n",
    "X_test_df = pd.DataFrame(X_test, columns=X.columns)  # Convert X_test to DataFrame\n",
    "\n",
    "# Save the corresponding target values (y_train, y_test) to CSV\n",
    "y_train_df = pd.DataFrame(y_train, columns=['COV1_OHD'])\n",
    "y_test_df = pd.DataFrame(y_test, columns=['COV1_OHD'])\n",
    "\n",
    "# Save the dataframes to CSV files with correct filenames in the correct directory\n",
    "X_train_df.to_csv(r'E:\\Research\\A NHTS\\NHTS Dataset\\X_train.csv', index=False)\n",
    "X_test_df.to_csv(r'E:\\Research\\A NHTS\\NHTS Dataset\\X_test.csv', index=False)\n",
    "y_train_df.to_csv(r'E:\\Research\\A NHTS\\NHTS Dataset\\y_train.csv', index=False)\n",
    "y_test_df.to_csv(r'E:\\Research\\A NHTS\\NHTS Dataset\\y_test.csv', index=False)\n",
    "\n",
    "print(\"Train and test datasets saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9ef9d86-4db0-45dd-9e42-e467e965fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3db5b27b-d128-45e0-a2f7-313993b38d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       704\n",
      "           1       1.00      0.93      0.96       850\n",
      "\n",
      "    accuracy                           0.96      1554\n",
      "   macro avg       0.96      0.96      0.96      1554\n",
      "weighted avg       0.96      0.96      0.96      1554\n",
      "\n",
      "Accuracy: 0.9588159588159588\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svm = SVC()\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = svm.predict(X_test_scaled)\n",
    "print(\"SVM Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1554631a-eceb-426a-9863-f3153378766c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       704\n",
      "           1       0.97      0.94      0.96       850\n",
      "\n",
      "    accuracy                           0.95      1554\n",
      "   macro avg       0.95      0.95      0.95      1554\n",
      "weighted avg       0.95      0.95      0.95      1554\n",
      "\n",
      "Accuracy: 0.9517374517374517\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)  # Fit the model with adjusted y_train\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Evaluate the XGBoost model\n",
    "print(\"XGBoost Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09117195-dc63-43f9-8234-4b0413862c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.62      0.70       704\n",
      "           1       0.73      0.87      0.80       850\n",
      "\n",
      "    accuracy                           0.76      1554\n",
      "   macro avg       0.77      0.74      0.75      1554\n",
      "weighted avg       0.76      0.76      0.75      1554\n",
      "\n",
      "Accuracy: 0.7561132561132561\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "print(\"Logistic Regression Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d2ee711-efda-4f3c-a02d-f560d3e19b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.62      0.70       704\n",
      "           1       0.73      0.87      0.80       850\n",
      "\n",
      "    accuracy                           0.76      1554\n",
      "   macro avg       0.77      0.74      0.75      1554\n",
      "weighted avg       0.76      0.76      0.75      1554\n",
      "\n",
      "Accuracy: 0.7561132561132561\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "print(\"Logistic Regression Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c01f4a0-fca5-42fe-a6ee-e8ef97436593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Variable        VIF\n",
      "0         const  40.029321\n",
      "1         R_AGE   1.307974\n",
      "2  HHFAMINC_IMP   1.530576\n",
      "3          EDUC   1.278855\n",
      "4    DELIV_FOOD   1.658692\n",
      "5    DELIV_GROC   1.594481\n",
      "6      COV2_OHD   1.017819\n",
      "7       COV1_WK   1.385392\n",
      "8       HOMEOWN   1.179927\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries if they are not already installed\n",
    "# !pip install pandas statsmodels\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Step 1: Load the merged dataset from the specified file path\n",
    "file_path = r\"E:\\Research\\A NHTS\\NHTS Dataset\\merged_data_clean.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: List of independent variables (using the variables that you selected)\n",
    "independent_vars = ['R_AGE', 'HHFAMINC_IMP', 'EDUC', 'DELIV_FOOD', 'DELIV_GROC', \n",
    "                    'COV2_OHD', 'COV1_WK', 'HOMEOWN']\n",
    "\n",
    "# Step 3: Subset the dataframe to include only the independent variables\n",
    "X = df[independent_vars]\n",
    "\n",
    "# Step 4: Add a constant (intercept) to the dataset for the VIF calculation\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Step 5: Calculate the VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Variable'] = X.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "# Step 6: Display the VIF results\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a5dc405-bcb5-47cc-9c54-a1de3b4f9742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (2.1.1)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn)\n",
      "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "Downloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: sklearn-compat, imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.13.0 sklearn-compat-0.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04aa50ff-5440-4f14-acf0-f60594820ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COV1_OHD\n",
      "1    4289\n",
      "0    3479\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🧪 Dataset split:\n",
      "Training set: 6862 samples\n",
      "Test set: 1716 samples\n",
      "Total after balancing: 8578 samples\n",
      "\n",
      "🚀 Training Logistic Regression...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.71      0.68       876\n",
      "           1       0.67      0.60      0.63       840\n",
      "\n",
      "    accuracy                           0.66      1716\n",
      "   macro avg       0.66      0.66      0.66      1716\n",
      "weighted avg       0.66      0.66      0.66      1716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[621 255]\n",
      " [333 507]]\n",
      "\n",
      "🚀 Training Naive Bayes...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94       876\n",
      "           1       0.94      0.92      0.93       840\n",
      "\n",
      "    accuracy                           0.93      1716\n",
      "   macro avg       0.93      0.93      0.93      1716\n",
      "weighted avg       0.93      0.93      0.93      1716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[830  46]\n",
      " [ 68 772]]\n",
      "\n",
      "🚀 Training SVM (RBF)...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       876\n",
      "           1       1.00      0.92      0.95       840\n",
      "\n",
      "    accuracy                           0.96      1716\n",
      "   macro avg       0.96      0.96      0.96      1716\n",
      "weighted avg       0.96      0.96      0.96      1716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[873   3]\n",
      " [ 70 770]]\n",
      "\n",
      "🚀 Training Random Forest...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       876\n",
      "           1       0.98      0.93      0.96       840\n",
      "\n",
      "    accuracy                           0.96      1716\n",
      "   macro avg       0.96      0.96      0.96      1716\n",
      "weighted avg       0.96      0.96      0.96      1716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[864  12]\n",
      " [ 60 780]]\n",
      "\n",
      "🚀 Training Decision Tree...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       876\n",
      "           1       0.93      0.94      0.93       840\n",
      "\n",
      "    accuracy                           0.94      1716\n",
      "   macro avg       0.94      0.94      0.94      1716\n",
      "weighted avg       0.94      0.94      0.94      1716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[812  64]\n",
      " [ 47 793]]\n",
      "\n",
      "🚀 Training K-Nearest Neighbors...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       876\n",
      "           1       0.96      0.91      0.94       840\n",
      "\n",
      "    accuracy                           0.94      1716\n",
      "   macro avg       0.94      0.94      0.94      1716\n",
      "weighted avg       0.94      0.94      0.94      1716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[844  32]\n",
      " [ 72 768]]\n",
      "\n",
      "🚀 Training SGD Classifier...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67       876\n",
      "           1       0.65      0.67      0.66       840\n",
      "\n",
      "    accuracy                           0.66      1716\n",
      "   macro avg       0.66      0.66      0.66      1716\n",
      "weighted avg       0.66      0.66      0.66      1716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[576 300]\n",
      " [277 563]]\n",
      "\n",
      "🚀 Training AdaBoost...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       876\n",
      "           1       0.99      0.93      0.96       840\n",
      "\n",
      "    accuracy                           0.96      1716\n",
      "   macro avg       0.96      0.96      0.96      1716\n",
      "weighted avg       0.96      0.96      0.96      1716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[869   7]\n",
      " [ 60 780]]\n",
      "\n",
      "🚀 Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:14:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       876\n",
      "           1       0.98      0.93      0.96       840\n",
      "\n",
      "    accuracy                           0.96      1716\n",
      "   macro avg       0.96      0.96      0.96      1716\n",
      "weighted avg       0.96      0.96      0.96      1716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[860  16]\n",
      " [ 55 785]]\n",
      "\n",
      "📊 Model Performance Summary (Train/Test Split):\n",
      "                     Accuracy  Precision  Recall  F1 Score\n",
      "Logistic Regression    0.6573     0.6654  0.6036    0.6330\n",
      "Naive Bayes            0.9336     0.9438  0.9190    0.9312\n",
      "SVM (RBF)              0.9575     0.9961  0.9167    0.9547\n",
      "Random Forest          0.9580     0.9848  0.9286    0.9559\n",
      "Decision Tree          0.9353     0.9253  0.9440    0.9346\n",
      "K-Nearest Neighbors    0.9394     0.9600  0.9143    0.9366\n",
      "SGD Classifier         0.6638     0.6524  0.6702    0.6612\n",
      "AdaBoost               0.9610     0.9911  0.9286    0.9588\n",
      "XGBoost                0.9586     0.9800  0.9345    0.9567\n",
      "\n",
      "🔁 5-Fold Cross-Validation (Accuracy):\n",
      "\n",
      "📦 Logistic Regression\n",
      "  Fold Accuracies : [0.6638 0.6737 0.7075 0.6787 0.684 ]\n",
      "  Mean Accuracy   : 0.6815\n",
      "----------------------------------------\n",
      "📦 Naive Bayes\n",
      "  Fold Accuracies : [0.9452 0.9283 0.9435 0.9376 0.9417]\n",
      "  Mean Accuracy   : 0.9393\n",
      "----------------------------------------\n",
      "📦 SVM (RBF)\n",
      "  Fold Accuracies : [0.9714 0.9545 0.9656 0.9609 0.9644]\n",
      "  Mean Accuracy   : 0.9634\n",
      "----------------------------------------\n",
      "📦 Random Forest\n",
      "  Fold Accuracies : [0.9656 0.954  0.9685 0.9574 0.9662]\n",
      "  Mean Accuracy   : 0.9623\n",
      "----------------------------------------\n",
      "📦 Decision Tree\n",
      "  Fold Accuracies : [0.9382 0.9254 0.9429 0.9411 0.9417]\n",
      "  Mean Accuracy   : 0.9379\n",
      "----------------------------------------\n",
      "📦 K-Nearest Neighbors\n",
      "  Fold Accuracies : [0.9569 0.9388 0.951  0.9539 0.9493]\n",
      "  Mean Accuracy   : 0.9500\n",
      "----------------------------------------\n",
      "📦 SGD Classifier\n",
      "  Fold Accuracies : [0.6364 0.5787 0.5519 0.6618 0.628 ]\n",
      "  Mean Accuracy   : 0.6113\n",
      "----------------------------------------\n",
      "📦 AdaBoost\n",
      "  Fold Accuracies : [0.9726 0.9575 0.9674 0.9621 0.9685]\n",
      "  Mean Accuracy   : 0.9656\n",
      "----------------------------------------\n",
      "📦 XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:15:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:15:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:15:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:15:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold Accuracies : [0.965  0.9575 0.9615 0.9592 0.9656]\n",
      "  Mean Accuracy   : 0.9618\n",
      "----------------------------------------\n",
      "\n",
      "📊 5-Fold Cross-Validation Accuracy Summary:\n",
      "                     5-Fold Accuracy\n",
      "AdaBoost                      0.9656\n",
      "SVM (RBF)                     0.9634\n",
      "Random Forest                 0.9623\n",
      "XGBoost                       0.9618\n",
      "K-Nearest Neighbors           0.9500\n",
      "Naive Bayes                   0.9393\n",
      "Decision Tree                 0.9379\n",
      "Logistic Regression           0.6815\n",
      "SGD Classifier                0.6113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:15:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# --------------------------------------------\n",
    "# 1. Load Dataset\n",
    "# --------------------------------------------\n",
    "df = pd.read_csv(r\"E:\\Research\\A NHTS\\NHTS Dataset\\merged_data_clean.csv\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# 2. Convert COV1_OHD to Binary (0 and 1) Based on Criteria\n",
    "# --------------------------------------------\n",
    "df['COV1_OHD'] = df['COV1_OHD'].apply(lambda x: 0 if x == 1 else (1 if x in [2, 3, 4] else x))\n",
    "\n",
    "# Check the distribution of the binary target variable\n",
    "print(df['COV1_OHD'].value_counts())\n",
    "\n",
    "# --------------------------------------------\n",
    "# 3. Define Target and Independent Variables\n",
    "# --------------------------------------------\n",
    "y = df['COV1_OHD']  # The updated binary target variable\n",
    "\n",
    "# Make sure to remove rows with missing values\n",
    "df = df.dropna(subset=['COV1_OHD'])  # Drop rows where 'COV1_OHD' is NaN\n",
    "\n",
    "# --------------------------------------------\n",
    "# 4. Define Final Independent Variables\n",
    "# --------------------------------------------\n",
    "iv_columns = [\n",
    "    'R_AGE', 'HHFAMINC_IMP', 'EDUC', 'HOMEOWN',\n",
    "    'DELIV_FOOD', 'DELIV_GROC', 'COV2_OHD', 'COV1_WK'\n",
    "]\n",
    "\n",
    "X = df[iv_columns].dropna()  # Ensure no missing values in the independent variables\n",
    "y = y.loc[X.index]  # Align the target variable with the independent variables\n",
    "\n",
    "# --------------------------------------------\n",
    "# 5. Balance Classes Using SMOTE\n",
    "# --------------------------------------------\n",
    "X_bal, y_bal = SMOTE(random_state=42).fit_resample(X, y)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 6. Train/Test Split\n",
    "# --------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bal, y_bal, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\n🧪 Dataset split:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Total after balancing: {X_bal.shape[0]} samples\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# 7. Scale Features (SVM, KNN, SGD)\n",
    "# --------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_bal_scaled = scaler.fit_transform(X_bal)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 8. Define Models\n",
    "# --------------------------------------------\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"SVM (RBF)\": SVC(kernel='rbf', probability=True),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"SGD Classifier\": SGDClassifier(loss='log_loss', max_iter=1000, tol=1e-3, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "}\n",
    "\n",
    "# --------------------------------------------\n",
    "# 9. Train and Evaluate on Train/Test Split\n",
    "# --------------------------------------------\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🚀 Training {name}...\")\n",
    "\n",
    "    if name in [\"SVM (RBF)\", \"SGD Classifier\", \"K-Nearest Neighbors\"]:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# --------------------------------------------\n",
    "# 10. Summary Table (Train/Test Split)\n",
    "# --------------------------------------------\n",
    "print(\"\\n📊 Model Performance Summary (Train/Test Split):\")\n",
    "summary_df = pd.DataFrame(results).T.round(4)\n",
    "print(summary_df)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 11. 5-Fold Cross-Validation (Accuracy)\n",
    "# --------------------------------------------\n",
    "print(\"\\n🔁 5-Fold Cross-Validation (Accuracy):\\n\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"📦 {name}\")\n",
    "    X_used = X_bal_scaled if name in [\"SVM (RBF)\", \"SGD Classifier\", \"K-Nearest Neighbors\"] else X_bal\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        model,\n",
    "        X=X_used,\n",
    "        y=y_bal,\n",
    "        scoring='accuracy',\n",
    "        cv=cv\n",
    "    )\n",
    "\n",
    "    print(f\"  Fold Accuracies : {np.round(scores, 4)}\")\n",
    "    print(f\"  Mean Accuracy   : {scores.mean():.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    cv_scores[name] = round(scores.mean(), 4)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 12. 5-Fold Accuracy Summary Table\n",
    "# --------------------------------------------\n",
    "print(\"\\n📊 5-Fold Cross-Validation Accuracy Summary:\")\n",
    "cv_df = pd.DataFrame.from_dict(cv_scores, orient='index', columns=['5-Fold Accuracy'])\n",
    "cv_df = cv_df.sort_values(by='5-Fold Accuracy', ascending=False)\n",
    "print(cv_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f25b9e-ab85-4a84-bedf-1e12da13b6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COV1_OHD\n",
      "1    4289\n",
      "0    3479\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🧪 Dataset split:\n",
      "Training set: 6862 samples\n",
      "Test set: 1716 samples\n",
      "Total after balancing: 8578 samples\n",
      "\n",
      "🚀 Training Logistic Regression...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.66       876\n",
      "           1       0.65      0.64      0.65       840\n",
      "\n",
      "    accuracy                           0.66      1716\n",
      "   macro avg       0.65      0.65      0.65      1716\n",
      "weighted avg       0.65      0.66      0.65      1716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[586 290]\n",
      " [302 538]]\n",
      "\n",
      "🚀 Training Naive Bayes...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       876\n",
      "           1       0.90      0.83      0.86       840\n",
      "\n",
      "    accuracy                           0.87      1716\n",
      "   macro avg       0.87      0.87      0.87      1716\n",
      "weighted avg       0.87      0.87      0.87      1716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[798  78]\n",
      " [144 696]]\n",
      "\n",
      "🚀 Training SVM (RBF)...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       876\n",
      "           1       0.99      0.92      0.95       840\n",
      "\n",
      "    accuracy                           0.96      1716\n",
      "   macro avg       0.96      0.96      0.96      1716\n",
      "weighted avg       0.96      0.96      0.96      1716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[872   4]\n",
      " [ 69 771]]\n",
      "\n",
      "🚀 Training Random Forest...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       876\n",
      "           1       0.99      0.93      0.96       840\n",
      "\n",
      "    accuracy                           0.96      1716\n",
      "   macro avg       0.96      0.96      0.96      1716\n",
      "weighted avg       0.96      0.96      0.96      1716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[868   8]\n",
      " [ 58 782]]\n",
      "\n",
      "🚀 Training Decision Tree...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94       876\n",
      "           1       0.93      0.94      0.93       840\n",
      "\n",
      "    accuracy                           0.93      1716\n",
      "   macro avg       0.93      0.93      0.93      1716\n",
      "weighted avg       0.93      0.93      0.93      1716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[815  61]\n",
      " [ 52 788]]\n",
      "\n",
      "🚀 Training K-Nearest Neighbors...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       876\n",
      "           1       0.86      0.88      0.87       840\n",
      "\n",
      "    accuracy                           0.87      1716\n",
      "   macro avg       0.87      0.87      0.87      1716\n",
      "weighted avg       0.87      0.87      0.87      1716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[753 123]\n",
      " [105 735]]\n",
      "\n",
      "🚀 Training SGD Classifier...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.64      0.62       876\n",
      "           1       0.59      0.55      0.57       840\n",
      "\n",
      "    accuracy                           0.59      1716\n",
      "   macro avg       0.59      0.59      0.59      1716\n",
      "weighted avg       0.59      0.59      0.59      1716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[560 316]\n",
      " [381 459]]\n",
      "\n",
      "🚀 Training AdaBoost...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       876\n",
      "           1       0.99      0.93      0.96       840\n",
      "\n",
      "    accuracy                           0.96      1716\n",
      "   macro avg       0.96      0.96      0.96      1716\n",
      "weighted avg       0.96      0.96      0.96      1716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[872   4]\n",
      " [ 62 778]]\n",
      "\n",
      "🚀 Training XGBoost...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       876\n",
      "           1       0.98      0.93      0.96       840\n",
      "\n",
      "    accuracy                           0.96      1716\n",
      "   macro avg       0.96      0.96      0.96      1716\n",
      "weighted avg       0.96      0.96      0.96      1716\n",
      "\n",
      "Confusion Matrix:\n",
      "[[861  15]\n",
      " [ 55 785]]\n",
      "\n",
      "📊 Model Performance Summary (Train/Test Split):\n",
      "                     Accuracy  Precision  Recall  F1 Score\n",
      "Logistic Regression    0.6550     0.6498  0.6405    0.6451\n",
      "Naive Bayes            0.8706     0.8992  0.8286    0.8625\n",
      "SVM (RBF)              0.9575     0.9948  0.9179    0.9548\n",
      "Random Forest          0.9615     0.9899  0.9310    0.9595\n",
      "Decision Tree          0.9341     0.9282  0.9381    0.9331\n",
      "K-Nearest Neighbors    0.8671     0.8566  0.8750    0.8657\n",
      "SGD Classifier         0.5938     0.5923  0.5464    0.5684\n",
      "AdaBoost               0.9615     0.9949  0.9262    0.9593\n",
      "XGBoost                0.9592     0.9812  0.9345    0.9573\n",
      "\n",
      "🔁 5-Fold Cross-Validation (Accuracy):\n",
      "\n",
      "📦 Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:37:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold Accuracies : [0.6649 0.6702 0.6941 0.6857 0.6793]\n",
      "  Mean Accuracy   : 0.6788\n",
      "----------------------------------------\n",
      "📦 Naive Bayes\n",
      "  Fold Accuracies : [0.8712 0.8683 0.8893 0.8776 0.8892]\n",
      "  Mean Accuracy   : 0.8791\n",
      "----------------------------------------\n",
      "📦 SVM (RBF)\n",
      "  Fold Accuracies : [0.9703 0.9551 0.9627 0.9603 0.9621]\n",
      "  Mean Accuracy   : 0.9621\n",
      "----------------------------------------\n",
      "📦 Random Forest\n",
      "  Fold Accuracies : [0.9679 0.9551 0.9668 0.9609 0.9673]\n",
      "  Mean Accuracy   : 0.9636\n",
      "----------------------------------------\n",
      "📦 Decision Tree\n",
      "  Fold Accuracies : [0.9487 0.9353 0.9435 0.93   0.944 ]\n",
      "  Mean Accuracy   : 0.9403\n",
      "----------------------------------------\n",
      "📦 K-Nearest Neighbors\n",
      "  Fold Accuracies : [0.8852 0.8631 0.88   0.8816 0.8741]\n",
      "  Mean Accuracy   : 0.8768\n",
      "----------------------------------------\n",
      "📦 SGD Classifier\n",
      "  Fold Accuracies : [0.5944 0.6952 0.6748 0.6093 0.6501]\n",
      "  Mean Accuracy   : 0.6448\n",
      "----------------------------------------\n",
      "📦 AdaBoost\n",
      "  Fold Accuracies : [0.9714 0.9575 0.9697 0.9638 0.9644]\n",
      "  Mean Accuracy   : 0.9654\n",
      "----------------------------------------\n",
      "📦 XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:38:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:38:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:38:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:38:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:38:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold Accuracies : [0.9656 0.9575 0.9679 0.9603 0.9656]\n",
      "  Mean Accuracy   : 0.9634\n",
      "----------------------------------------\n",
      "\n",
      "📊 5-Fold Cross-Validation Accuracy Summary:\n",
      "                     5-Fold Accuracy\n",
      "AdaBoost                      0.9654\n",
      "Random Forest                 0.9636\n",
      "XGBoost                       0.9634\n",
      "SVM (RBF)                     0.9621\n",
      "Decision Tree                 0.9403\n",
      "Naive Bayes                   0.8791\n",
      "K-Nearest Neighbors           0.8768\n",
      "Logistic Regression           0.6788\n",
      "SGD Classifier                0.6448\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# --------------------------------------------\n",
    "# 1. Load Dataset\n",
    "# --------------------------------------------\n",
    "df = pd.read_csv(r\"E:\\Research\\A NHTS\\NHTS Dataset\\merged_data_clean.csv\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# 2. Convert COV1_OHD to Binary (0 and 1) Based on Criteria\n",
    "# --------------------------------------------\n",
    "df['COV1_OHD'] = df['COV1_OHD'].apply(lambda x: 0 if x == 1 else (1 if x in [2, 3, 4] else x))\n",
    "\n",
    "# Check the distribution of the binary target variable\n",
    "print(df['COV1_OHD'].value_counts())\n",
    "\n",
    "# --------------------------------------------\n",
    "# 3. Define Target and Independent Variables\n",
    "# --------------------------------------------\n",
    "y = df['COV1_OHD']  # The updated binary target variable\n",
    "\n",
    "# Make sure to remove rows with missing values\n",
    "df = df.dropna(subset=['COV1_OHD'])  # Drop rows where 'COV1_OHD' is NaN\n",
    "\n",
    "# --------------------------------------------\n",
    "# 4. Define Final Independent Variables\n",
    "# --------------------------------------------\n",
    "iv_columns = [\n",
    "    'R_AGE', 'HHFAMINC_IMP', 'EDUC', 'HOMEOWN',\n",
    "    'HHSIZE', 'DELIV_FOOD', 'DELIV_GROC', 'DELIV_GOOD', \n",
    "    'COV2_OHD', 'COV1_WK', 'WRKCOUNT', 'LIF_CYC', 'URBRUR', 'MSACAT'\n",
    "]\n",
    "\n",
    "X = df[iv_columns].dropna()  # Ensure no missing values in the independent variables\n",
    "y = y.loc[X.index]  # Align the target variable with the independent variables\n",
    "\n",
    "# --------------------------------------------\n",
    "# 5. Balance Classes Using SMOTE\n",
    "# --------------------------------------------\n",
    "X_bal, y_bal = SMOTE(random_state=42).fit_resample(X, y)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 6. Train/Test Split\n",
    "# --------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bal, y_bal, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\n🧪 Dataset split:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Total after balancing: {X_bal.shape[0]} samples\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# 7. Scale Features (SVM, KNN, SGD)\n",
    "# --------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_bal_scaled = scaler.fit_transform(X_bal)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 8. Define Models\n",
    "# --------------------------------------------\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"SVM (RBF)\": SVC(kernel='rbf', probability=True),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"SGD Classifier\": SGDClassifier(loss='log_loss', max_iter=1000, tol=1e-3, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "}\n",
    "\n",
    "# --------------------------------------------\n",
    "# 9. Train and Evaluate on Train/Test Split\n",
    "# --------------------------------------------\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🚀 Training {name}...\")\n",
    "\n",
    "    if name in [\"SVM (RBF)\", \"SGD Classifier\", \"K-Nearest Neighbors\"]:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# --------------------------------------------\n",
    "# 10. Summary Table (Train/Test Split)\n",
    "# --------------------------------------------\n",
    "print(\"\\n📊 Model Performance Summary (Train/Test Split):\")\n",
    "summary_df = pd.DataFrame(results).T.round(4)\n",
    "print(summary_df)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 11. 5-Fold Cross-Validation (Accuracy)\n",
    "# --------------------------------------------\n",
    "print(\"\\n🔁 5-Fold Cross-Validation (Accuracy):\\n\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"📦 {name}\")\n",
    "    X_used = X_bal_scaled if name in [\"SVM (RBF)\", \"SGD Classifier\", \"K-Nearest Neighbors\"] else X_bal\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        model,\n",
    "        X=X_used,\n",
    "        y=y_bal,\n",
    "        scoring='accuracy',\n",
    "        cv=cv\n",
    "    )\n",
    "\n",
    "    print(f\"  Fold Accuracies : {np.round(scores, 4)}\")\n",
    "    print(f\"  Mean Accuracy   : {scores.mean():.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    cv_scores[name] = round(scores.mean(), 4)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 12. 5-Fold Accuracy Summary Table\n",
    "# --------------------------------------------\n",
    "print(\"\\n📊 5-Fold Cross-Validation Accuracy Summary:\")\n",
    "cv_df = pd.DataFrame.from_dict(cv_scores, orient='index', columns=['5-Fold Accuracy'])\n",
    "cv_df = cv_df.sort_values(by='5-Fold Accuracy', ascending=False)\n",
    "print(cv_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dbfc351-01e9-41e1-a986-e98e7295ef29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Variable        VIF\n",
      "0          const  73.666475\n",
      "1          R_AGE   2.261371\n",
      "2   HHFAMINC_IMP   1.752683\n",
      "3           EDUC   1.329706\n",
      "4        HOMEOWN   1.242743\n",
      "5         HHSIZE   1.644864\n",
      "6     DELIV_FOOD   1.676033\n",
      "7     DELIV_GROC   1.602387\n",
      "8     DELIV_GOOD   1.117242\n",
      "9       COV2_OHD   1.030311\n",
      "10       COV1_WK   2.145028\n",
      "11      WRKCOUNT   2.663177\n",
      "12       LIF_CYC   2.043388\n",
      "13        URBRUR   1.213329\n",
      "14        MSACAT   1.245051\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries if they are not already installed\n",
    "# !pip install pandas statsmodels\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Step 1: Load the merged dataset from the specified file path\n",
    "file_path = r\"E:\\Research\\A NHTS\\NHTS Dataset\\merged_data_clean.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: List of independent variables (using the variables that you selected)\n",
    "independent_vars = ['R_AGE', 'HHFAMINC_IMP', 'EDUC', 'HOMEOWN', \n",
    "                    'HHSIZE', 'DELIV_FOOD', 'DELIV_GROC', 'DELIV_GOOD', \n",
    "                    'COV2_OHD', 'COV1_WK', 'WRKCOUNT', 'LIF_CYC', 'URBRUR', 'MSACAT']\n",
    "\n",
    "# Step 3: Subset the dataframe to include only the independent variables\n",
    "X = df[independent_vars]\n",
    "\n",
    "# Step 4: Add a constant (intercept) to the dataset for the VIF calculation\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Step 5: Calculate the VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Variable'] = X.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "# Step 6: Display the VIF results\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fa6831-8b1d-4382-b59e-4499c36cce19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
